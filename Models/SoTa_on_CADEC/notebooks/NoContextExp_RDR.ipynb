{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "directed-butter",
   "metadata": {},
   "source": [
    "<h3>Векторизуем словарь Meddra</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collected-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorization import ConceptVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "white-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модели нам не нужны, ведь вложения получены в ячейке fit_transform() и сохранены, поэтому use_model = False\n",
    "#чтобы получить вложения, надо вызвать CV с use_model = True и вызвать fit_transform\n",
    "CV_train = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                             use_concept_less=False, use_model=False)\n",
    "CV_test = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                            use_concept_less=True, use_model=False)\n",
    "CV_test_without_conceptless = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                            use_concept_less=False, use_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_train.meddra_term_to_meddra_code['Сомнолентность']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regular-wallet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting concept embeddings in mean_pooling mode...\n",
      "moving to cuda... device name cuda:0\n",
      "Compute embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25077/25077 [04:37<00:00, 90.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding aggregation...\n",
      "Concept embeddings have computed in 277.1238613128662 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CV_train.fit_transform(mode='mean_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flush-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(CV_train.thesaurus_embeddings, 'rubert_thesaurus_embeddings_meddra_origin.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sustainable-spoke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "CV_train.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings_meddra_origin.pt')\n",
    "CV_train.normalization_mode = 'mean_pooling'\n",
    "\n",
    "CV_test.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings_meddra_origin.pt')\n",
    "CV_test.normalization_mode = 'mean_pooling'\n",
    "\n",
    "CV_test_without_conceptless.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings_meddra_origin.pt')\n",
    "CV_test_without_conceptless.normalization_mode = 'mean_pooling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-concrete",
   "metadata": {},
   "source": [
    "<h3>Создадим датасет RDR</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "egyptian-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "earlier-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "with jsonlines.open('../../Data/Raw/medNorm_16022022.jsonlines') as reader:\n",
    "    for obj in reader:\n",
    "        ds.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "material-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(ds, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minute-illinois",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего фраз в трейне: 8121\n",
      "Всего фраз в тесте: 4006\n",
      "Уникальных фраз в трейне: 4382\n",
      "Уникальных фраз в тесте: 2408\n",
      "545 концептов не входящих либо в трейн, либо в тест\n",
      "147 концептов, которые есть в тесте, но нет в трейне\n",
      "398 концептов, которые есть в трейне, но нет в тесте\n"
     ]
    }
   ],
   "source": [
    "#выцепим фразы с нормализацией по Meddra без их контекста\n",
    "train_phrases = []\n",
    "train_sentences = []\n",
    "train_concepts = []\n",
    "\n",
    "test_phrases = []\n",
    "test_sentences = []\n",
    "test_concepts = []\n",
    "\n",
    "test_phrases_without_conceptless = []\n",
    "test_concepts_without_conceptless = []\n",
    "\n",
    "log_markup_errors = []\n",
    "\n",
    "#в трейне не будем собирать conceptless термины\n",
    "USE_CONCEPT_LESS = False\n",
    "for review in X_train:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                if USE_CONCEPT_LESS:\n",
    "                    ent['MedDRA'] = 'CONCEPT_LESS'\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                train_concepts.append(CV_train.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "                train_phrases.append(ent['text'])\n",
    "            except KeyError:\n",
    "                log_markup_errors.append({'review_id': review['meta']['fileName'], 'entity_id': ent['xmiID']})\n",
    "            \n",
    "\n",
    "USE_CONCEPT_LESS = True\n",
    "for review in X_test:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                if USE_CONCEPT_LESS:\n",
    "                    ent['MedDRA'] = 'CONCEPT_LESS'\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                test_concepts.append(CV_test.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "                test_phrases.append(ent['text'])\n",
    "            except KeyError:\n",
    "                log_markup_errors.append({'review_id': review['meta']['fileName'], 'entity_id': ent['xmiID']})\n",
    "                \n",
    "USE_CONCEPT_LESS = False\n",
    "for review in X_test:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                if USE_CONCEPT_LESS:\n",
    "                    ent['MedDRA'] = 'CONCEPT_LESS'\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                test_concepts_without_conceptless.append(CV_test_without_conceptless.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "                test_phrases_without_conceptless.append(ent['text'])\n",
    "            except KeyError:\n",
    "                #log_markup_errors.append({'review_id': review['meta']['fileName'], 'entity_id': ent['xmiID']})\n",
    "                pass\n",
    "            \n",
    "print('Всего фраз в трейне: %s'%len(train_phrases))\n",
    "print('Всего фраз в тесте: %s'%len(test_phrases))\n",
    "\n",
    "print('Уникальных фраз в трейне: %s'%len(set(train_phrases)))\n",
    "print('Уникальных фраз в тесте: %s'%len(set(test_phrases)))\n",
    "\n",
    "#Посмотрим на статистику разбиения\n",
    "print('%s концептов не входящих либо в трейн, либо в тест'%len(set.union(set(train_concepts), set(test_concepts)) - set.intersection(set(test_concepts), set(train_concepts))))\n",
    "print('%s концептов, которые есть в тесте, но нет в трейне'%len(set(test_concepts) - set(train_concepts)))\n",
    "print('%s концептов, которые есть в трейне, но нет в тесте'%len(set(train_concepts) - set(test_concepts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "narrative-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "from dataset import MedNormDataset\n",
    "\n",
    "RDR_train = MedNormDataset(train_phrases, train_concepts, CV_train, use_cuda=True)\n",
    "RDR_test = MedNormDataset(test_phrases, test_concepts, CV_test, use_cuda=True)\n",
    "RDR_test_without_concepless = MedNormDataset(test_phrases_without_conceptless, test_concepts_without_conceptless, CV_test_without_conceptless, use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-actor",
   "metadata": {},
   "source": [
    "тест модельки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impossible-liberty",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loaded\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from collections import UserDict\n",
    "\n",
    "class CADEC_SoTa_output(UserDict):\n",
    "    def __init__(self, output):\n",
    "        if type(output)==dict:\n",
    "            super(CADEC_SoTa_output, self).__init__(output)\n",
    "        else:\n",
    "            super(CADEC_SoTa_output, self).__init__()\n",
    "            self.data['output'] = output\n",
    "            self.data['has_padding_for_conceptless_class'] = False\n",
    "    def to(self, device: str):\n",
    "        self.data = {k: v.to(device=device) for k, v in self.data.items()}\n",
    "    def pad_output(self):\n",
    "        #нулевой класс должен быть под индексом 1\n",
    "        self.data['output'] = torch.cat((torch.zeros((*(self.data['output'].size()[:-1]), 1), \\\n",
    "                               device = self.data['output'].device), self.data['output']), dim=-1)\n",
    "        self.data['has_padding_for_conceptless_class'] = True     \n",
    "    def delete_padding(self):\n",
    "        self.data['output'] = self.data['output'][:,1:]\n",
    "        self.data['has_padding_for_conceptless_class'] = False        \n",
    "    def compute_scores(self):\n",
    "        self.data['max_scores'] = torch.max(self.data['output'], dim=-1)[0]\n",
    "    def mask_conceptless(self, score_treshold):\n",
    "        self.compute_scores()\n",
    "        concept_exists_term_mask = self.data['max_scores'][:]>score_treshold\n",
    "        concept_less_term_mask = ~concept_exists_term_mask\n",
    "        return concept_less_term_mask\n",
    "    def label_concepless_tensors(self, score_treshold):\n",
    "        self.pad_output()\n",
    "        concept_less_tensor = torch.zeros(self.data['output'].size()[-1], dtype=self.data['output'].dtype, device=self.data['output'].device)\n",
    "        concept_less_tensor[0]=1\n",
    "        self.data['output'][self.mask_conceptless(score_treshold)] = concept_less_tensor\n",
    "\n",
    "class CADEC_SoTa(nn.Module):\n",
    "    def __init__(self, model_path: str, thesaurus_embeddings: torch.tensor):\n",
    "        super(CADEC_SoTa, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_path)\n",
    "        self.thesaurus_len, self.hidden_state_size = thesaurus_embeddings.size()\n",
    "        self.thesaurus_normalized_embs = nn.Parameter(self._normalize_embeddings(thesaurus_embeddings), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        transformer_inp = {k:v for k,v in x.items() if k in ['input_ids', 'token_type_ids', 'attention_mask']}\n",
    "        emb = self.transformer(**transformer_inp)\n",
    "        term_mask = transformer_inp['attention_mask'] if 'input_phrases_masks' not in x.keys() else x['input_phrases_masks']\n",
    "        x = self._mean_pooling(emb, term_mask)\n",
    "        #имеем две матрицы x - (batch_size, emb_size) и thesaurus_embeddings - (thesaurus_size, emb_size)\n",
    "        #надо посчитать косинусную близость близость между каждым вектором x и каждым вложением из тезауруса\n",
    "        #решение: https://stackoverflow.com/questions/50411191/how-to-compute-the-cosine-similarity-in-pytorch-for-all-rows-in-a-matrix-with-re\n",
    "        x_n = x.norm(dim=1)[:, None] \n",
    "        x_n = x / torch.clamp(x_n, min=1e-8)\n",
    "        cos_sim = torch.mm(x_n, self.thesaurus_normalized_embs)\n",
    "        x = F.softmax(cos_sim, dim=1)\n",
    "        return CADEC_SoTa_output(x)\n",
    "    \n",
    "    \n",
    "    def _normalize_embeddings(self, emb):\n",
    "        normalized_embs = emb.norm(dim=1)[:, None]\n",
    "        normalized_embs = emb / torch.clamp(normalized_embs, min=1e-8)\n",
    "        normalized_embs = normalized_embs.transpose(0, 1)\n",
    "        return normalized_embs\n",
    "    \n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-8)\n",
    "\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "net = CADEC_SoTa(model_path, CV_train.thesaurus_embeddings) #, score_threshold=6.1977e-05\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "print('Net loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smoking-injury",
   "metadata": {},
   "source": [
    "Демонстрация работы с concept_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "egyptian-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: сонливость\n",
      "model: Сонливость новорожденных\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "net.eval()\n",
    "phrase = 'сонливость'\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "encoded_input = tokenizer([phrase], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_dict = net(encoded_input.to('cuda'))\n",
    "    outputs_dict.label_concepless_tensors(score_treshold=6.1977e-05)\n",
    "    pred_meddra_code = CV_test.meddra_codes[outputs_dict['output'].argmax()]\n",
    "    \n",
    "print('phrase: %s'%phrase)\n",
    "print('model: %s'%CV_test.meddra_code_to_meddra_term[pred_meddra_code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-salem",
   "metadata": {},
   "source": [
    "<h2>Обучение модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "annual-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)\n",
    "#optimizer2 = optim.AdamW(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "immediate-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-universe",
   "metadata": {},
   "source": [
    "Для большей детерменированности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noble-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n",
    "torch.use_deterministic_algorithms(mode=False)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "according-tobacco",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 508/508 [00:53<00:00,  9.45batch/s, loss_decrease=1.0000013180507235]\n",
      "100%|██████████| 3787/3787 [00:43<00:00, 86.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5901769210456826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 508/508 [00:54<00:00,  9.26batch/s, loss_decrease=1.0000016004906163]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.76batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646686031159229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 508/508 [00:53<00:00,  9.43batch/s, loss_decrease=1.0000020712241255]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.23batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722999735938738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 508/508 [00:51<00:00,  9.77batch/s, loss_decrease=1.0000026361049215]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.31batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931608133086876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 508/508 [00:54<00:00,  9.38batch/s, loss_decrease=1.0000030126924735]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.27batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7087404277792446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 508/508 [00:53<00:00,  9.46batch/s, loss_decrease=1.0000032009863558]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7200950620543967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 508/508 [00:48<00:00, 10.55batch/s, loss_decrease=1.0000034834273122]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.01batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7232637972009505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 508/508 [00:46<00:00, 10.86batch/s, loss_decrease=1.0000034834273122]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 99.36batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7282809611829945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 508/508 [00:53<00:00,  9.45batch/s, loss_decrease=1.000003577574333] \n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.13batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7288090837074201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 508/508 [00:35<00:00, 14.21batch/s, loss_decrease=1.000003765868428] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.63batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732241880116187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 508/508 [00:53<00:00,  9.41batch/s, loss_decrease=1.0000038600155021]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.76batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7375231053604437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 508/508 [00:52<00:00,  9.72batch/s, loss_decrease=1.0000038600155021]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 94.74batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7380512278848693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 508/508 [00:51<00:00,  9.89batch/s, loss_decrease=1.000003954162594] \n",
      "100%|██████████| 3787/3787 [00:38<00:00, 98.21batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428043306047003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 508/508 [00:51<00:00,  9.86batch/s, loss_decrease=1.0000040483097037]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.41batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7404277792447848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 508/508 [00:51<00:00,  9.88batch/s, loss_decrease=1.0000040483097037]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.82batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7472933720623185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 508/508 [00:52<00:00,  9.64batch/s, loss_decrease=1.0000040483097037]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.92batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7454449432268286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 508/508 [00:45<00:00, 11.21batch/s, loss_decrease=1.0000040483097037]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 97.00batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7441246369157644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 508/508 [00:53<00:00,  9.55batch/s, loss_decrease=1.000004142456831] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.91batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7488777396355955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 508/508 [00:50<00:00, 10.00batch/s, loss_decrease=1.000004142456831] \n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.16batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7483496171111698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 508/508 [00:45<00:00, 11.11batch/s, loss_decrease=1.000004142456831] \n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.98batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7467652495378928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 508/508 [00:52<00:00,  9.64batch/s, loss_decrease=1.000004142456831] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.33batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7486136783733827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 508/508 [00:46<00:00, 10.89batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.45batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7517824135199367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 508/508 [00:48<00:00, 10.42batch/s, loss_decrease=1.0000042366039759]\n",
      "100%|██████████| 3787/3787 [00:41<00:00, 91.78batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7523105360443623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 508/508 [00:54<00:00,  9.29batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.66batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7536308423554264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 508/508 [00:52<00:00,  9.71batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.61batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541589648798521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 508/508 [00:53<00:00,  9.57batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.19batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525745973065753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 508/508 [00:50<00:00, 10.15batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.14batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541589648798521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 508/508 [00:46<00:00, 11.04batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 99.50batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552152099287035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 508/508 [00:50<00:00, 10.13batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.59batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7549511486664905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 508/508 [00:52<00:00,  9.59batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.86batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7525745973065753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 508/508 [00:54<00:00,  9.38batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.03batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7594401901241087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 508/508 [00:51<00:00,  9.93batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.43batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759176128861896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 508/508 [00:43<00:00, 11.61batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.51batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567995775019805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 508/508 [00:51<00:00,  9.79batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:40<00:00, 94.51batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565355162397677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 508/508 [00:52<00:00,  9.60batch/s, loss_decrease=1.0000042366039759]\n",
      "100%|██████████| 3787/3787 [00:41<00:00, 92.04batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7362027990493794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 508/508 [00:52<00:00,  9.67batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:43<00:00, 87.12batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7578558225508318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 508/508 [00:47<00:00, 10.66batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.75batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567995775019805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 508/508 [00:51<00:00,  9.86batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:41<00:00, 90.90batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7531027198310007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 508/508 [00:54<00:00,  9.33batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.18batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541589648798521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 508/508 [00:54<00:00,  9.29batch/s, loss_decrease=1.0000043307511386]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.06batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7586480063374703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 508/508 [00:52<00:00,  9.64batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.31batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7520464747821495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 508/508 [00:54<00:00,  9.38batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.40batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7552152099287035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 508/508 [00:51<00:00,  9.81batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.49batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7581198838130445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 508/508 [00:48<00:00, 10.58batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 94.94batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7599683126485345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 508/508 [00:53<00:00,  9.48batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.34batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7565355162397677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 508/508 [00:46<00:00, 10.97batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.26batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759176128861896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 508/508 [00:54<00:00,  9.30batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.65batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7567995775019805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 508/508 [00:53<00:00,  9.55batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.30batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7618167414840243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 508/508 [00:53<00:00,  9.43batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.21batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7602323739107472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 508/508 [00:48<00:00, 10.52batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.96batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76234486400845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 508/508 [00:53<00:00,  9.49batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.69batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759176128861896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 508/508 [00:50<00:00,  9.96batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 96.88batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620808027462371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 508/508 [00:43<00:00, 11.74batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.26batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620808027462371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 508/508 [00:51<00:00,  9.85batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 98.23batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7620808027462371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 508/508 [00:52<00:00,  9.64batch/s, loss_decrease=1.000004424898319] \n",
      "100%|██████████| 3787/3787 [00:39<00:00, 94.80batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7604964351729602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 508/508 [00:52<00:00,  9.71batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 93.02batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7612886189595987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 508/508 [00:53<00:00,  9.43batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:40<00:00, 94.17batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76234486400845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 508/508 [00:53<00:00,  9.57batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:39<00:00, 95.80batch/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760760496435173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 508/508 [00:53<00:00,  9.43batch/s, loss_decrease=1.0000045190455173]\n",
      "100%|██████████| 3787/3787 [00:38<00:00, 97.85batch/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7612886189595987\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "batch_size=16\n",
    "trainloader = torch.utils.data.DataLoader(RDR_train, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(RDR_test_without_concepless, batch_size=1, shuffle=False)\n",
    "\n",
    "net.train()\n",
    "initial_loss = None\n",
    "for epoch in range(1, 60):\n",
    "    net.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            labels = data['one_hot_labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if device=='cuda':\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = net(inputs)['output']\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = net(inputs)['output']\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if initial_loss is None:\n",
    "                initial_loss = loss.item()\n",
    "            tepoch.set_postfix(loss_decrease = str(initial_loss/loss.item()))\n",
    "    net.eval()\n",
    "    model_answers=[]\n",
    "    real_answers=[]\n",
    "    with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "        for data in eval_process:\n",
    "\n",
    "            #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            #labels = data['one_hot_labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs_dict = net(inputs)\n",
    "                #outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "                pred_meddra_code = CV_test_without_conceptless.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "            model_answers.append(pred_meddra_code)\n",
    "            real_answers.append(data['label_codes'])\n",
    "\n",
    "    print(f1_score(real_answers, model_answers, average='micro'))\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-hearts",
   "metadata": {},
   "source": [
    "<h2>Другие метрики и сохранение выхода</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "metallic-module",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3780/3780 [00:44<00:00, 84.77batch/s]\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 weighted: 0.7112716468879845\n",
      "f1 micro: 0.7343915343915344\n",
      "f1 macro: 0.21946400048543566\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from models import CADEC_SoTa\n",
    "\n",
    "\n",
    "net = torch.load('rubert_9ep_best_nocontext.pt')\n",
    "net.eval()\n",
    "\n",
    "out_of_voc_set = set(test_concepts) - set(train_concepts)\n",
    "\n",
    "phrases=[]\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "model_terms=[]\n",
    "real_terms=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test_without_concepless, batch_size=1, shuffle=False)\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_dict = net(inputs)\n",
    "            #outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "            pred_meddra_code = CV_test_without_conceptless.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "        phrases.append(data['phrases'][0])\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'][0])\n",
    "        model_terms.append(CV_test_without_conceptless.meddra_code_to_meddra_term[pred_meddra_code])\n",
    "        real_terms.append(data['label_terms'][0])\n",
    "        \n",
    "res_d = classification_report(real_answers, model_answers, output_dict=True)\n",
    "print('f1 weighted: %s'%res_d['weighted avg']['f1-score'])\n",
    "print('f1 micro: %s'%res_d['accuracy'])\n",
    "print('f1 macro: %s'%res_d['macro avg']['f1-score'])\n",
    "\n",
    "df = pd.DataFrame(columns=['phrase', 'system output', 'gold markup', 'pred term', 'gold term', 'out_of_voc'])\n",
    "for phrase, m_a, g_a, m_t, g_t in zip(phrases, model_answers, real_answers, model_terms, real_terms):\n",
    "    out_of_voc = 'yes' if g_a in out_of_voc_set else 'no'\n",
    "    new_row = pd.DataFrame({'phrase': [phrase], 'system output': [m_a], \n",
    "                            'gold markup': [g_a], 'pred term': [m_t], 'gold term': [g_t], 'out_of_voc': out_of_voc})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    \n",
    "    \n",
    "df.to_csv('rubert_9ep_best_nocontext_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "motivated-admission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 weighted in: 0.756517331859167\n",
      "f1 micro in: 0.7720178372352285\n",
      "f1 macro in: 0.3066816723272698\n",
      "f1 weighted out: 0.03757440476190476\n",
      "f1 micro out: 0.03125\n",
      "f1 macro out: 0.017214799588900306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_out = df[df['out_of_voc']=='yes']\n",
    "df_in = df[df['out_of_voc']=='no']\n",
    "\n",
    "res_d_in = classification_report(df_in['gold markup'], df_in['system output'], output_dict=True)\n",
    "res_d_out = classification_report(df_out['gold markup'], df_out['system output'], output_dict=True)\n",
    "\n",
    "print('f1 weighted in: %s'%res_d_in['weighted avg']['f1-score'])\n",
    "print('f1 micro in: %s'%res_d_in['accuracy'])\n",
    "print('f1 macro in: %s'%res_d_in['macro avg']['f1-score'])\n",
    "\n",
    "print('f1 weighted out: %s'%res_d_out['weighted avg']['f1-score'])\n",
    "print('f1 micro out: %s'%res_d_out['accuracy'])\n",
    "print('f1 macro out: %s'%res_d_out['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-quarterly",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling c CONCEPT_LESS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unexpected-nudist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3999/3999 [00:41<00:00, 96.32batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.695173793448362"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_dict = net(inputs)\n",
    "            outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "            pred_meddra_code = CV_test.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "appointed-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': tensor([[3.9106e-05, 4.1192e-05, 4.0345e-05,  ..., 4.0723e-05, 3.8689e-05,\n",
       "         3.7171e-05]], device='cuda:0'), 'max_scores': tensor([8.9186e-05], device='cuda:0')}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-freight",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "moderate-parking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1749/1749 [00:20<00:00, 83.56batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8147512864493998"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-emperor",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "multiple-disposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:17<00:00, 98.77batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7994285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "meaning-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:21<00:00, 81.52batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "saved-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:20<00:00, 87.42batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'][0])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-honolulu",
   "metadata": {},
   "source": [
    "<h2> Тест необученной модели (на всякий случай) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pending-magic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:05<00:00, 294.15batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17142857142857143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#net.train()\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-fifty",
   "metadata": {},
   "source": [
    "<h2>Инференс</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "answering-dating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: температурой 37,8\n",
      "model: Пирексия\n",
      "real: Пирексия\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "#i = randint(1, len(RDR_test))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "#phrase = {k: tensor.unsqueeze(0) for k, tensor in RDR_test[i]['tokenized_phrases'].items()}\n",
    "concept = RDR_test[i]['label_codes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_answer = CV.meddra_codes[net(phrase).argmax()]\n",
    "    \n",
    "\n",
    "\n",
    "print('phrase: %s'%RDR_test[i]['phrases'])\n",
    "print('model: %s'%CV.meddra_code_to_meddra_term[model_answer])\n",
    "\n",
    "\n",
    "\n",
    "print('real: %s'%RDR_test[i]['label_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-pioneer",
   "metadata": {},
   "source": [
    "Где ошиблась модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "automotive-canberra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:19<00:00, 88.99batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>раздрожалась</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>чувство тревоги</td>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>угнетенном состоянии</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Начала плохо спать</td>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ухудшилось эмоциональное состояние</td>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>проблема с кожей на лице</td>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>шаткая нервная система</td>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>острой респираторной вирусной инфекции</td>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>с гнойно-слизистым секретом</td>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>37,3</td>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     phrase system output gold markup\n",
       "0                              раздрожалась      10025482    10022998\n",
       "1                           чувство тревоги      10033670    10002855\n",
       "2                      угнетенном состоянии      10025482    10040007\n",
       "3                        Начала плохо спать      10022437    10062519\n",
       "4        ухудшилось эмоциональное состояние      10061284    10014551\n",
       "..                                      ...           ...         ...\n",
       "359                проблема с кожей на лице      10015150    10000496\n",
       "360                  шаткая нервная система      10029216    10003549\n",
       "361  острой респираторной вирусной инфекции      10074831    10062352\n",
       "362             с гнойно-слизистым секретом      10023848    10039083\n",
       "363                                    37,3      10037660    10005911\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = torch.load('./cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')['param_groups']\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_wrong_answers = []\n",
    "gold_truth_answers = []\n",
    "phrases = []\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "        \n",
    "        if str(pred_meddra_code)!=str(data['label_codes'][0]):\n",
    "            model_wrong_answers.append(pred_meddra_code)\n",
    "            gold_truth_answers.append(data['label_codes'][0])\n",
    "            phrases.append(data['phrases'][0])\n",
    "        #model_wrong_answers\n",
    "        #model_answers.append(pred_meddra_code)\n",
    "        #real_answers.append(data['label_codes'])\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['phrase', 'system output', 'gold markup'])\n",
    "\n",
    "for phrase, m_a, g_a in zip(phrases, model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'phrase': [phrase], 'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "immediate-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "closed-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.meddra_code_to_meddra_term['CONCEPT_LESS'] = 'CONCEPT_LESS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "circular-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>для профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>стрессы</td>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "      <td>Стресс</td>\n",
       "      <td>Стресс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>тревожности</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10033670</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Паническая реакция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>ослабленного иммунитета</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10021425</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Нарушение со стороны иммунной системы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>чихал</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10041232</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Чихание</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>кашлял</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10011224</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Кашель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>температура</td>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phrase system output  gold markup  \\\n",
       "0                профилактики      10036898     10036898   \n",
       "1            для профилактики      10036898     10036898   \n",
       "2                профилактики      10036898     10036898   \n",
       "3                профилактики      10036898     10036898   \n",
       "4                     стрессы      10042209     10042209   \n",
       "...                       ...           ...          ...   \n",
       "1745              тревожности  CONCEPT_LESS     10033670   \n",
       "1746  ослабленного иммунитета  CONCEPT_LESS     10021425   \n",
       "1747                    чихал  CONCEPT_LESS     10041232   \n",
       "1748                   кашлял  CONCEPT_LESS     10011224   \n",
       "1749              температура      10005911     10005911   \n",
       "\n",
       "                   system concept                           gold concept  \n",
       "0                    Профилактика                           Профилактика  \n",
       "1                    Профилактика                           Профилактика  \n",
       "2                    Профилактика                           Профилактика  \n",
       "3                    Профилактика                           Профилактика  \n",
       "4                          Стресс                                 Стресс  \n",
       "...                           ...                                    ...  \n",
       "1745                 CONCEPT_LESS                     Паническая реакция  \n",
       "1746                 CONCEPT_LESS  Нарушение со стороны иммунной системы  \n",
       "1747                 CONCEPT_LESS                                Чихание  \n",
       "1748                 CONCEPT_LESS                                 Кашель  \n",
       "1749  Повышенная температура тела            Повышенная температура тела  \n",
       "\n",
       "[1750 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('elastic_wrong_predictions.csv')\n",
    "df['system concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['system output'])], axis=1)#], join='outer', ignore_index=True)\n",
    "df['gold concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['gold markup'])], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "median-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong = df[df['system output'].apply(lambda x: int(x) if x!='CONCEPT_LESS' else 'CONCEPT_LESS')!=df['gold markup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dedicated-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phrase, system output, gold markup, system concept, gold concept]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong[df_wrong['system output']!='CONCEPT_LESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "periodic-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong.to_csv('elastic_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "opponent-alignment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "1745    True\n",
       "1746    True\n",
       "1747    True\n",
       "1748    True\n",
       "1749    True\n",
       "Length: 1750, dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "gentle-chester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           10036898\n",
       "1           10036898\n",
       "2           10036898\n",
       "3           10036898\n",
       "4           10042209\n",
       "            ...     \n",
       "1745    CONCEPT_LESS\n",
       "1746    CONCEPT_LESS\n",
       "1747    CONCEPT_LESS\n",
       "1748    CONCEPT_LESS\n",
       "1749        10005911\n",
       "Name: system output, Length: 1750, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aggregate-break",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10036898\n",
       "1       10036898\n",
       "2       10036898\n",
       "3       10036898\n",
       "4       10042209\n",
       "          ...   \n",
       "1745    10033670\n",
       "1746    10021425\n",
       "1747    10041232\n",
       "1748    10011224\n",
       "1749    10005911\n",
       "Name: gold markup, Length: 1750, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "framed-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_wrong_preds_RDR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "industrial-proportion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output  gold markup\n",
       "0         10025482     10022998\n",
       "1         10033670     10002855\n",
       "2         10025482     10040007\n",
       "3         10022437     10062519\n",
       "4         10061284     10014551\n",
       "..             ...          ...\n",
       "359       10015150     10000496\n",
       "360       10029216     10003549\n",
       "361       10074831     10062352\n",
       "362       10023848     10039083\n",
       "363       10037660     10005911\n",
       "\n",
       "[364 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "israeli-geography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10033670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>10021425</td>\n",
       "      <td>10021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>10041232</td>\n",
       "      <td>10041232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>10011224</td>\n",
       "      <td>10011224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output gold markup\n",
       "0         10036898    10036898\n",
       "1         10036898    10036898\n",
       "2         10036898    10036898\n",
       "3         10036898    10036898\n",
       "4         10042209    10042209\n",
       "...            ...         ...\n",
       "1745      10033670    10033670\n",
       "1746      10021425    10021425\n",
       "1747      10041232    10041232\n",
       "1748      10011224    10011224\n",
       "1749      10005911    10005911\n",
       "\n",
       "[1750 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['system output', 'gold markup'])\n",
    "\n",
    "for m_a, g_a in zip(model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fleet-agriculture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-patient",
   "metadata": {},
   "source": [
    "<h2>Сохранение и загрузка модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "surprised-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')\n",
    "torch.save(optimizer.state_dict(), './cadec_SoTa_on_RDR_rubert_base_2_epoch_opt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "secure-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = torch.load('./cadec_SoTa_on_RDR_rubert_right_exp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-world",
   "metadata": {},
   "source": [
    "Покажем, что это ТА ЖЕ модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "separated-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:06<00:00, 259.93batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5891428571428572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[the_model(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-sampling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normalization env",
   "language": "python",
   "name": "latest_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
