{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "after-chester",
   "metadata": {},
   "source": [
    "<h3>Векторизуем словарь Meddra</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flush-booking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorization import ConceptVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "known-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "#модели нам не нужны, ведь вложения получены в ячейке fit_transform() и сохранены, поэтому use_model = False\n",
    "#чтобы получить вложения, надо вызвать CV с use_model = True и вызвать fit_transform в расчете вложений словаря\n",
    "CV = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                             use_concept_less=False, use_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complicated-court",
   "metadata": {},
   "source": [
    "Расчет вложений словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "higher-immunology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting concept embeddings in mean_pooling mode...\n",
      "Compute embeddings...\n",
      "Embedding aggregation...\n"
     ]
    }
   ],
   "source": [
    "#используется только для рассчетов вложений словаря\n",
    "#когда они готовы, проще их загрузить ячейкой с загрузкой\n",
    "CV.fit_transform(mode='mean_pooling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-decline",
   "metadata": {},
   "source": [
    "Сохранение рассчитанных вложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-explosion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(CV.thesaurus_embeddings, 'rubert_thesaurus_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-illustration",
   "metadata": {},
   "source": [
    "Загрузка готовых вложений (если они есть). Загружать вложения после fit_transform() не надо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "global-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "CV.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings.pt')\n",
    "CV.normalization_mode = 'mean_pooling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conscious-india",
   "metadata": {},
   "source": [
    "<h3>Создадим датасет RDR</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polyphonic-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flush-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "with jsonlines.open('../../Data/Raw/medNorm_16022022.jsonlines') as reader:\n",
    "    for obj in reader:\n",
    "        ds.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "marine-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(ds, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "speaking-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего фраз в трейне: 8104\n",
      "Всего фраз в тесте: 0\n",
      "Уникальных фраз в трейне: 4365\n",
      "Уникальных фраз в тесте: 0\n",
      "784 концептов не входящих либо в трейн, либо в тест\n",
      "0 концептов, которые есть в тесте, но нет в трейне\n",
      "784 концептов, которые есть в трейне, но нет в тесте\n"
     ]
    }
   ],
   "source": [
    "#выцепим фразы с нормализацией по Meddra без их контекста\n",
    "train_phrases = []\n",
    "train_sentences = []\n",
    "train_concepts = []\n",
    "\n",
    "test_phrases = []\n",
    "test_sentences = []\n",
    "test_concepts = []\n",
    "\n",
    "test_phrases_without_conceptless = []\n",
    "test_concepts_without_conceptless = []\n",
    "\n",
    "log_markup_errors = []\n",
    "\n",
    "#в трейне не будем собирать conceptless термины\n",
    "\n",
    "USE_CONCEPT_LESS = False\n",
    "\n",
    "for review in X_train:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                if USE_CONCEPT_LESS:\n",
    "                    ent['MedDRA'] = 'CONCEPT_LESS'\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                train_concepts.append(CV.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "                train_phrases.append(ent['text'])\n",
    "            except KeyError:\n",
    "                log_markup_errors.append({'review_id': review['meta']['fileName'], 'entity_id': ent['xmiID']})\n",
    "                \n",
    "for review in X_test:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                if USE_CONCEPT_LESS:\n",
    "                    ent['MedDRA'] = 'CONCEPT_LESS'\n",
    "                else:\n",
    "                    continue\n",
    "            try:\n",
    "                test_concepts_without_conceptless.append(CV.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "                test_phrases_without_conceptless.append(ent['text'])\n",
    "            except KeyError:\n",
    "                #log_markup_errors.append({'review_id': review['meta']['fileName'], 'entity_id': ent['xmiID']})\n",
    "                pass\n",
    "            \n",
    "print('Всего фраз в трейне: %s'%len(train_phrases))\n",
    "print('Всего фраз в тесте: %s'%len(test_phrases))\n",
    "\n",
    "print('Уникальных фраз в трейне: %s'%len(set(train_phrases)))\n",
    "print('Уникальных фраз в тесте: %s'%len(set(test_phrases)))\n",
    "\n",
    "#Посмотрим на статистику разбиения\n",
    "print('%s концептов не входящих либо в трейн, либо в тест'%len(set.union(set(train_concepts), set(test_concepts)) - set.intersection(set(test_concepts), set(train_concepts))))\n",
    "print('%s концептов, которые есть в тесте, но нет в трейне'%len(set(test_concepts) - set(train_concepts)))\n",
    "print('%s концептов, которые есть в трейне, но нет в тесте'%len(set(train_concepts) - set(test_concepts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MedNormDataset\n",
    "\n",
    "RDR_train = MedNormDataset(train_phrases, train_concepts, CV, use_cuda=True)\n",
    "RDR_test = MedNormDataset(test_phrases, test_concepts, CV, use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-correspondence",
   "metadata": {},
   "source": [
    "<h2>Импорт модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "square-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loaded\n"
     ]
    }
   ],
   "source": [
    "from models import CADEC_SoTa\n",
    "\n",
    "\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "net = CADEC_SoTa(model_path, CV.thesaurus_embeddings) #, score_threshold=6.1977e-05\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "print('Net loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-trail",
   "metadata": {},
   "source": [
    "Демонстрация работы с concept_less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "toxic-creature",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: сонливость\n",
      "model: Аномалия специальных видов чувствительности врожденная\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "net.eval()\n",
    "phrase = 'сонливость'\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "encoded_input = tokenizer([phrase], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_dict = net(encoded_input.to('cuda'))\n",
    "    outputs_dict.label_concepless_tensors(score_treshold=6.1977e-05)\n",
    "    pred_meddra_code = CV.meddra_codes[outputs_dict['output'].argmax()]\n",
    "    \n",
    "print('phrase: %s'%phrase)\n",
    "print('model: %s'%CV.meddra_code_to_meddra_term[pred_meddra_code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-recruitment",
   "metadata": {},
   "source": [
    "<h2>Обучение модели c логированием  wandb</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_WANDB= False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sharing-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hydraulic-breed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.defaults['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "focused-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-liquid",
   "metadata": {},
   "source": [
    "Для большей детерменированности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "local-insight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n",
    "torch.use_deterministic_algorithms(mode=False)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "utility-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RDR_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_WANDB:\n\u001b[1;32m      8\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m      9\u001b[0m       project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedNormalization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m     10\u001b[0m       config\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: epochs,\n\u001b[1;32m     16\u001b[0m       })\n\u001b[0;32m---> 18\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\u001b[43mRDR_train\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     19\u001b[0m                                           shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m testloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(RDR_test_without_concepless, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RDR_train' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "batch_size=16\n",
    "epochs = 1\n",
    "if USE_WANDB:\n",
    "    wandb.init(\n",
    "      project=\"MedNormalization\", \n",
    "      config={\n",
    "      \"learning_rate\": optimizer.defaults['lr'],\n",
    "      \"batch_size\": batch_size,\n",
    "      \"architecture\": \"CADEC_SoTa\",\n",
    "      \"dataset\": \"RDR\",\n",
    "      \"epochs\": epochs,\n",
    "      })\n",
    "    \n",
    "trainloader = torch.utils.data.DataLoader(RDR_train, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1, shuffle=False)\n",
    "\n",
    "net.train()\n",
    "initial_loss = None\n",
    "for epoch in range(1, epochs):\n",
    "    net.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            labels = data['one_hot_labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if device=='cuda':\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = net(inputs)['output']\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = net(inputs)['output']\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if initial_loss is None:\n",
    "                initial_loss = loss.item()\n",
    "            tepoch.set_postfix(loss_decrease = str(initial_loss/loss.item()))\n",
    "    net.eval()\n",
    "    model_answers=[]\n",
    "    real_answers=[]\n",
    "    with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "        for data in eval_process:\n",
    "\n",
    "            #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            #labels = data['one_hot_labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs_dict = net(inputs)\n",
    "                #outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "                pred_meddra_code = CV_test_without_conceptless.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "            model_answers.append(pred_meddra_code)\n",
    "            real_answers.append(data['label_codes'])\n",
    "\n",
    "    print(f1_score(real_answers, model_answers, average='micro'))\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-chuck",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling c CONCEPT_LESS</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improving-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3999/3999 [00:41<00:00, 96.32batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.695173793448362"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_dict = net(inputs)\n",
    "            outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "            pred_meddra_code = CV_test.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "prepared-practitioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': tensor([[3.9106e-05, 4.1192e-05, 4.0345e-05,  ..., 4.0723e-05, 3.8689e-05,\n",
       "         3.7171e-05]], device='cuda:0'), 'max_scores': tensor([8.9186e-05], device='cuda:0')}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-tracker",
   "metadata": {},
   "source": [
    "Инференс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "thick-encyclopedia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: Хуй соси губой тряси ff\n",
      "model: Гнев\n"
     ]
    }
   ],
   "source": [
    "phrase = 'Хуй соси губой тряси ff'\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "encoded_input = tokenizer([phrase], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_dict = net(inputs)\n",
    "    outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "    pred_meddra_code = CV.meddra_codes[outputs_dict['output'].argmax()]\n",
    "    \n",
    "print('phrase: %s'%phrase)\n",
    "print('model: %s'%CV.meddra_code_to_meddra_term[pred_meddra_code])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-identifier",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "southern-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1749/1749 [00:20<00:00, 83.56batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8147512864493998"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-soundtrack",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "peaceful-saturn",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:17<00:00, 98.77batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7994285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pressing-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:21<00:00, 81.52batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "current-comparison",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:20<00:00, 87.42batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'][0])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-atlas",
   "metadata": {},
   "source": [
    "<h2> Тест необученной модели (на всякий случай) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "instant-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:05<00:00, 294.15batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17142857142857143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#net.train()\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-latest",
   "metadata": {},
   "source": [
    "<h2>Инференс</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "binding-gasoline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: температурой 37,8\n",
      "model: Пирексия\n",
      "real: Пирексия\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "#i = randint(1, len(RDR_test))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "#phrase = {k: tensor.unsqueeze(0) for k, tensor in RDR_test[i]['tokenized_phrases'].items()}\n",
    "concept = RDR_test[i]['label_codes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_answer = CV.meddra_codes[net(phrase).argmax()]\n",
    "    \n",
    "\n",
    "\n",
    "print('phrase: %s'%RDR_test[i]['phrases'])\n",
    "print('model: %s'%CV.meddra_code_to_meddra_term[model_answer])\n",
    "\n",
    "\n",
    "\n",
    "print('real: %s'%RDR_test[i]['label_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-interference",
   "metadata": {},
   "source": [
    "Где ошиблась модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "grand-wages",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:19<00:00, 88.99batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>раздрожалась</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>чувство тревоги</td>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>угнетенном состоянии</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Начала плохо спать</td>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ухудшилось эмоциональное состояние</td>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>проблема с кожей на лице</td>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>шаткая нервная система</td>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>острой респираторной вирусной инфекции</td>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>с гнойно-слизистым секретом</td>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>37,3</td>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     phrase system output gold markup\n",
       "0                              раздрожалась      10025482    10022998\n",
       "1                           чувство тревоги      10033670    10002855\n",
       "2                      угнетенном состоянии      10025482    10040007\n",
       "3                        Начала плохо спать      10022437    10062519\n",
       "4        ухудшилось эмоциональное состояние      10061284    10014551\n",
       "..                                      ...           ...         ...\n",
       "359                проблема с кожей на лице      10015150    10000496\n",
       "360                  шаткая нервная система      10029216    10003549\n",
       "361  острой респираторной вирусной инфекции      10074831    10062352\n",
       "362             с гнойно-слизистым секретом      10023848    10039083\n",
       "363                                    37,3      10037660    10005911\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = torch.load('./cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')['param_groups']\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_wrong_answers = []\n",
    "gold_truth_answers = []\n",
    "phrases = []\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "        \n",
    "        if str(pred_meddra_code)!=str(data['label_codes'][0]):\n",
    "            model_wrong_answers.append(pred_meddra_code)\n",
    "            gold_truth_answers.append(data['label_codes'][0])\n",
    "            phrases.append(data['phrases'][0])\n",
    "        #model_wrong_answers\n",
    "        #model_answers.append(pred_meddra_code)\n",
    "        #real_answers.append(data['label_codes'])\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['phrase', 'system output', 'gold markup'])\n",
    "\n",
    "for phrase, m_a, g_a in zip(phrases, model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'phrase': [phrase], 'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "headed-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "irish-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.meddra_code_to_meddra_term['CONCEPT_LESS'] = 'CONCEPT_LESS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "serious-diameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>для профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>стрессы</td>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "      <td>Стресс</td>\n",
       "      <td>Стресс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>тревожности</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10033670</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Паническая реакция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>ослабленного иммунитета</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10021425</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Нарушение со стороны иммунной системы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>чихал</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10041232</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Чихание</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>кашлял</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10011224</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Кашель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>температура</td>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phrase system output  gold markup  \\\n",
       "0                профилактики      10036898     10036898   \n",
       "1            для профилактики      10036898     10036898   \n",
       "2                профилактики      10036898     10036898   \n",
       "3                профилактики      10036898     10036898   \n",
       "4                     стрессы      10042209     10042209   \n",
       "...                       ...           ...          ...   \n",
       "1745              тревожности  CONCEPT_LESS     10033670   \n",
       "1746  ослабленного иммунитета  CONCEPT_LESS     10021425   \n",
       "1747                    чихал  CONCEPT_LESS     10041232   \n",
       "1748                   кашлял  CONCEPT_LESS     10011224   \n",
       "1749              температура      10005911     10005911   \n",
       "\n",
       "                   system concept                           gold concept  \n",
       "0                    Профилактика                           Профилактика  \n",
       "1                    Профилактика                           Профилактика  \n",
       "2                    Профилактика                           Профилактика  \n",
       "3                    Профилактика                           Профилактика  \n",
       "4                          Стресс                                 Стресс  \n",
       "...                           ...                                    ...  \n",
       "1745                 CONCEPT_LESS                     Паническая реакция  \n",
       "1746                 CONCEPT_LESS  Нарушение со стороны иммунной системы  \n",
       "1747                 CONCEPT_LESS                                Чихание  \n",
       "1748                 CONCEPT_LESS                                 Кашель  \n",
       "1749  Повышенная температура тела            Повышенная температура тела  \n",
       "\n",
       "[1750 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('elastic_wrong_predictions.csv')\n",
    "df['system concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['system output'])], axis=1)#], join='outer', ignore_index=True)\n",
    "df['gold concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['gold markup'])], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "czech-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong = df[df['system output'].apply(lambda x: int(x) if x!='CONCEPT_LESS' else 'CONCEPT_LESS')!=df['gold markup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abstract-romantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phrase, system output, gold markup, system concept, gold concept]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong[df_wrong['system output']!='CONCEPT_LESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "macro-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong.to_csv('elastic_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "million-particle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "1745    True\n",
       "1746    True\n",
       "1747    True\n",
       "1748    True\n",
       "1749    True\n",
       "Length: 1750, dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "technological-telling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           10036898\n",
       "1           10036898\n",
       "2           10036898\n",
       "3           10036898\n",
       "4           10042209\n",
       "            ...     \n",
       "1745    CONCEPT_LESS\n",
       "1746    CONCEPT_LESS\n",
       "1747    CONCEPT_LESS\n",
       "1748    CONCEPT_LESS\n",
       "1749        10005911\n",
       "Name: system output, Length: 1750, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "changing-cartoon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10036898\n",
       "1       10036898\n",
       "2       10036898\n",
       "3       10036898\n",
       "4       10042209\n",
       "          ...   \n",
       "1745    10033670\n",
       "1746    10021425\n",
       "1747    10041232\n",
       "1748    10011224\n",
       "1749    10005911\n",
       "Name: gold markup, Length: 1750, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "lesser-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_wrong_preds_RDR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "widespread-packing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output  gold markup\n",
       "0         10025482     10022998\n",
       "1         10033670     10002855\n",
       "2         10025482     10040007\n",
       "3         10022437     10062519\n",
       "4         10061284     10014551\n",
       "..             ...          ...\n",
       "359       10015150     10000496\n",
       "360       10029216     10003549\n",
       "361       10074831     10062352\n",
       "362       10023848     10039083\n",
       "363       10037660     10005911\n",
       "\n",
       "[364 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vietnamese-february",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10033670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>10021425</td>\n",
       "      <td>10021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>10041232</td>\n",
       "      <td>10041232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>10011224</td>\n",
       "      <td>10011224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output gold markup\n",
       "0         10036898    10036898\n",
       "1         10036898    10036898\n",
       "2         10036898    10036898\n",
       "3         10036898    10036898\n",
       "4         10042209    10042209\n",
       "...            ...         ...\n",
       "1745      10033670    10033670\n",
       "1746      10021425    10021425\n",
       "1747      10041232    10041232\n",
       "1748      10011224    10011224\n",
       "1749      10005911    10005911\n",
       "\n",
       "[1750 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['system output', 'gold markup'])\n",
    "\n",
    "for m_a, g_a in zip(model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "phantom-transition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-cleaning",
   "metadata": {},
   "source": [
    "<h2>Сохранение и загрузка модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "maritime-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')\n",
    "torch.save(optimizer.state_dict(), './cadec_SoTa_on_RDR_rubert_base_2_epoch_opt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "identical-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = torch.load('./cadec_SoTa_on_RDR_rubert_right_exp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-mumbai",
   "metadata": {},
   "source": [
    "Покажем, что это ТА ЖЕ модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "innovative-scroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:06<00:00, 259.93batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5891428571428572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[the_model(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-reasoning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest_torch",
   "language": "python",
   "name": "latest_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
