{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "restricted-strike",
   "metadata": {},
   "source": [
    "<h3>Векторизуем словарь Meddra</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-premium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vectorization import ConceptVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "turkish-husband",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#модели нам не нужны, ведь вложения получены в ячейке fit_transform() и сохранены, поэтому use_model = False\n",
    "#чтобы получить вложения, надо вызвать CV с use_model = True и вызвать fit_transform\n",
    "CV_train = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                             use_concept_less=False, use_model=False)\n",
    "CV_test = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                            use_concept_less=True, use_model=False)\n",
    "CV_test_without_conceptless = ConceptVectorizer('DeepPavlov/rubert-base-cased', '../../Data/External/pt_rus.asc', \\\n",
    "                            use_concept_less=False, use_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "economic-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting concept embeddings in mean_pooling mode...\n",
      "Compute embeddings...\n",
      "Embedding aggregation...\n"
     ]
    }
   ],
   "source": [
    "CV.fit_transform(mode='mean_pooling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-israeli",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.thesaurus_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(CV.thesaurus_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23954, 768])\n"
     ]
    }
   ],
   "source": [
    "print(CV.thesaurus_embeddings.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "impressed-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(CV.thesaurus_embeddings, 'rubert_thesaurus_embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "passive-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "CV_train.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings.pt')\n",
    "CV_train.normalization_mode = 'mean_pooling'\n",
    "\n",
    "CV_test.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings.pt')\n",
    "CV_test.normalization_mode = 'mean_pooling'\n",
    "\n",
    "CV_test_without_conceptless.thesaurus_embeddings = torch.load('rubert_thesaurus_embeddings.pt')\n",
    "CV_test_without_conceptless.normalization_mode = 'mean_pooling'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-superior",
   "metadata": {},
   "source": [
    "<h3>Создадим датасет RDR</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forbidden-queens",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structural-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = []\n",
    "with jsonlines.open('../../Data/Raw/medNorm_16022022.jsonlines') as reader:\n",
    "    for obj in reader:\n",
    "        ds.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bigger-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ADE-Neg',\n",
       " 'ADR',\n",
       " 'BNE-Pos',\n",
       " 'Disease',\n",
       " 'Diseasename',\n",
       " 'Indication',\n",
       " 'NegatedADE',\n",
       " 'Worse'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_types = set()\n",
    "for review in ds:\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            ent_types.add(ent['MedEntityType'])\n",
    "        if 'DisType' in ent.keys():\n",
    "            ent_types.add(ent['DisType'])\n",
    "            \n",
    "ent_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "explicit-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(ds, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quantitative-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "printable-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenizer = nltk.tokenize.PunktSentenceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southern-serial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "no sent found\n",
      "Всего фраз в трейне: 8099\n",
      "Всего фраз в тесте: 3995\n",
      "Уникальных фраз в трейне: 4360\n",
      "Уникальных фраз в тесте: 2397\n",
      "539 концептов не входящих либо в трейн, либо в тест\n",
      "145 концептов, которые есть в тесте, но нет в трейне\n",
      "394 концептов, которые есть в трейне, но нет в тесте\n"
     ]
    }
   ],
   "source": [
    "#выцепим фразы с нормализацией по Meddra без их контекста\n",
    "\n",
    "train_phrases = []\n",
    "train_sentences = []\n",
    "train_concepts = []\n",
    "\n",
    "test_phrases = []\n",
    "test_sentences = []\n",
    "test_concepts = []\n",
    "\n",
    "test_phrases_without_conceptless = []\n",
    "test_sentences_without_conceptless = []\n",
    "test_concepts_without_conceptless = []\n",
    "\n",
    "for review in X_train:\n",
    "    doc_sentences_spans = list(sent_tokenizer.span_tokenize(review['raw']))\n",
    "    doc_sentences = list(sent_tokenizer.sentences_from_text(review['raw']))\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys() and ent['MedDRA']!='':\n",
    "            #в каком предложении?\n",
    "            ent_begin = ent['spans'][0]['begin']\n",
    "            ent_end = ent['spans'][-1]['end']\n",
    "            for sent_id, sentence_span in enumerate(doc_sentences_spans):\n",
    "                if ent_begin >= sentence_span[0] and ent_end <= sentence_span[1]:\n",
    "                    break\n",
    "            else:\n",
    "                print('no sent found')\n",
    "                continue\n",
    "            phrase_spans_in_sentence = [[span['begin'] - sentence_span[0], \n",
    "                                        span['end'] - sentence_span[0]] for span in ent['spans']]\n",
    "            try:\n",
    "                train_concepts.append(CV_train.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "            except:\n",
    "                continue\n",
    "            train_sentences.append({'sentence': doc_sentences[sent_id], \n",
    "                                   'phrase': ent['text'], \n",
    "                                   'phrase_spans': phrase_spans_in_sentence})\n",
    "            train_phrases.append(ent['text'])\n",
    "            \n",
    "            \n",
    "for review in X_test:\n",
    "    doc_sentences_spans = list(sent_tokenizer.span_tokenize(review['raw']))\n",
    "    doc_sentences = list(sent_tokenizer.sentences_from_text(review['raw']))\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                ent['MedDRA']='CONCEPT_LESS'\n",
    "            #в каком предложении?\n",
    "            ent_begin = ent['spans'][0]['begin']\n",
    "            ent_end = ent['spans'][-1]['end']\n",
    "            for sent_id, sentence_span in enumerate(doc_sentences_spans):\n",
    "                if ent_begin >= sentence_span[0] and ent_end <= sentence_span[1]:\n",
    "                    break\n",
    "            else:\n",
    "                print('no sent found')\n",
    "                continue\n",
    "            phrase_spans_in_sentence = [[span['begin'] - sentence_span[0], \n",
    "                                        span['end'] - sentence_span[0]] for span in ent['spans']]\n",
    "            try:\n",
    "                test_concepts.append(CV_test.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "            except:\n",
    "                continue\n",
    "            test_sentences.append({'sentence': doc_sentences[sent_id], \n",
    "                                  'phrase': ent['text'], \n",
    "                                  'phrase_spans': phrase_spans_in_sentence})\n",
    "            test_phrases.append(ent['text'])\n",
    "            \n",
    "for review in X_test:\n",
    "    doc_sentences_spans = list(sent_tokenizer.span_tokenize(review['raw']))\n",
    "    doc_sentences = list(sent_tokenizer.sentences_from_text(review['raw']))\n",
    "    for ent in review['objects']['MedEntity']:\n",
    "        if 'MedDRA' in ent.keys():\n",
    "            if ent['MedDRA']=='':\n",
    "                continue\n",
    "            #в каком предложении?\n",
    "            ent_begin = ent['spans'][0]['begin']\n",
    "            ent_end = ent['spans'][-1]['end']\n",
    "            for sent_id, sentence_span in enumerate(doc_sentences_spans):\n",
    "                if ent_begin >= sentence_span[0] and ent_end <= sentence_span[1]:\n",
    "                    break\n",
    "            else:\n",
    "                print('no sent found')\n",
    "                continue\n",
    "            phrase_spans_in_sentence = [[span['begin'] - sentence_span[0], \n",
    "                                        span['end'] - sentence_span[0]] for span in ent['spans']]\n",
    "            try:\n",
    "                 test_concepts_without_conceptless.append(CV_test_without_conceptless.meddra_term_to_meddra_code[ent['MedDRA'].split('|')[0]])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            test_sentences_without_conceptless.append({'sentence': doc_sentences[sent_id], \n",
    "                                  'phrase': ent['text'], \n",
    "                                  'phrase_spans': phrase_spans_in_sentence})\n",
    "            test_phrases_without_conceptless.append(ent['text'])\n",
    "            \n",
    "print('Всего фраз в трейне: %s'%len(train_phrases))\n",
    "print('Всего фраз в тесте: %s'%len(test_phrases))\n",
    "\n",
    "print('Уникальных фраз в трейне: %s'%len(set(train_phrases)))\n",
    "print('Уникальных фраз в тесте: %s'%len(set(test_phrases)))\n",
    "\n",
    "#Посмотрим на статистику разбиения\n",
    "print('%s концептов не входящих либо в трейн, либо в тест'%len(set.union(set(train_concepts), set(test_concepts)) - set.intersection(set(test_concepts), set(train_concepts))))\n",
    "print('%s концептов, которые есть в тесте, но нет в трейне'%len(set(test_concepts) - set(train_concepts)))\n",
    "print('%s концептов, которые есть в трейне, но нет в тесте'%len(set(train_concepts) - set(test_concepts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "complete-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import MedNormContextDataset\n",
    "\n",
    "RDR_train = MedNormContextDataset(train_sentences, train_concepts, CV_train, use_cuda=True)\n",
    "RDR_test = MedNormContextDataset(test_sentences, test_concepts, CV_test, use_cuda=True)\n",
    "RDR_test_without_conceptless = MedNormContextDataset(test_sentences_without_conceptless, test_concepts_without_conceptless, CV_test_without_conceptless, use_cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-effects",
   "metadata": {},
   "source": [
    "тест модельки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "assured-mixture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net loaded\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModel\n",
    "from collections import UserDict\n",
    "\n",
    "class CADEC_SoTa_output(UserDict):\n",
    "    def __init__(self, output):\n",
    "        if type(output)==dict:\n",
    "            super(CADEC_SoTa_output, self).__init__(output)\n",
    "        else:\n",
    "            super(CADEC_SoTa_output, self).__init__()\n",
    "            self.data['output'] = output\n",
    "            self.data['has_padding_for_conceptless_class'] = False\n",
    "    def to(self, device: str):\n",
    "        self.data = {k: v.to(device=device) for k, v in self.data.items()}\n",
    "    def pad_output(self):\n",
    "        #нулевой класс должен быть под индексом 1\n",
    "        self.data['output'] = torch.cat((torch.zeros((*(self.data['output'].size()[:-1]), 1), \\\n",
    "                               device = self.data['output'].device), self.data['output']), dim=-1)\n",
    "        self.data['has_padding_for_conceptless_class'] = True     \n",
    "    def delete_padding(self):\n",
    "        self.data['output'] = self.data['output'][:,1:]\n",
    "        self.data['has_padding_for_conceptless_class'] = False        \n",
    "    def compute_scores(self):\n",
    "        self.data['max_scores'] = torch.max(self.data['output'], dim=-1)[0]\n",
    "    def mask_conceptless(self, score_treshold):\n",
    "        self.compute_scores()\n",
    "        concept_exists_term_mask = self.data['max_scores'][:]>score_treshold\n",
    "        concept_less_term_mask = ~concept_exists_term_mask\n",
    "        return concept_less_term_mask\n",
    "    def label_concepless_tensors(self, score_treshold):\n",
    "        self.pad_output()\n",
    "        concept_less_tensor = torch.zeros(self.data['output'].size()[-1], dtype=self.data['output'].dtype, device=self.data['output'].device)\n",
    "        concept_less_tensor[0]=1\n",
    "        self.data['output'][self.mask_conceptless(score_treshold)] = concept_less_tensor\n",
    "\n",
    "class CADEC_SoTa(nn.Module):\n",
    "    def __init__(self, model_path: str, thesaurus_embeddings: torch.tensor):\n",
    "        super(CADEC_SoTa, self).__init__()\n",
    "        self.transformer = AutoModel.from_pretrained(model_path)\n",
    "        self.thesaurus_len, self.hidden_state_size = thesaurus_embeddings.size()\n",
    "        self.thesaurus_normalized_embs = nn.Parameter(self._normalize_embeddings(thesaurus_embeddings), requires_grad=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        transformer_inp = {k:v for k,v in x.items() if k in ['input_ids', 'token_type_ids', 'attention_mask']}\n",
    "        emb = self.transformer(**transformer_inp)\n",
    "        term_mask = transformer_inp['attention_mask'] if 'input_phrases_masks' not in x.keys() else x['input_phrases_masks']\n",
    "        x = self._mean_pooling(emb, term_mask)\n",
    "        #имеем две матрицы x - (batch_size, emb_size) и thesaurus_embeddings - (thesaurus_size, emb_size)\n",
    "        #надо посчитать косинусную близость близость между каждым вектором x и каждым вложением из тезауруса\n",
    "        #решение: https://stackoverflow.com/questions/50411191/how-to-compute-the-cosine-similarity-in-pytorch-for-all-rows-in-a-matrix-with-re\n",
    "        x_n = x.norm(dim=1)[:, None] \n",
    "        x_n = x / torch.clamp(x_n, min=1e-8)\n",
    "        cos_sim = torch.mm(x_n, self.thesaurus_normalized_embs)\n",
    "        x = F.softmax(cos_sim, dim=1)\n",
    "        return CADEC_SoTa_output(x)\n",
    "    \n",
    "    #def _filter_concept_less(self, x):\n",
    "        #pad x\n",
    "        #x = torch.cat((torch.zeros((*(x.size()[:-1]), 1), device = 'cuda'), x), dim=-1) так запарнее\n",
    "    #    max_scores = torch.max(x, dim=-1)[0]\n",
    "    #    concept_exists_term_mask = max_scores[:]>self.score_threshold\n",
    "    #    concept_less_term_mask = ~concept_exists_term_mask\n",
    "    #    x[concept_less_term_mask] = self.concept_less_tensor\n",
    "    #    return x\n",
    "    \n",
    "    def _normalize_embeddings(self, emb):\n",
    "        #if self.score_threshold:\n",
    "        #    emb = torch.cat((torch.zeros((1, self.hidden_state_size)), emb), dim=0)\n",
    "        normalized_embs = emb.norm(dim=1)[:, None]\n",
    "        normalized_embs = emb / torch.clamp(normalized_embs, min=1e-8)\n",
    "        normalized_embs = normalized_embs.transpose(0, 1)\n",
    "        return normalized_embs\n",
    "    \n",
    "    def _mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-8)\n",
    "\n",
    "\n",
    "\n",
    "#как инициализировать модель\n",
    "#модель path - путь до трансформер модели\n",
    "#CV.thesaurus_embeddings - векторизованный словарь меддры\n",
    "\n",
    "#import torch\n",
    "\n",
    "#net = Net(model_path, CV.thesaurus_embeddings)\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#net.to(device)\n",
    "#print('Net loaded')\n",
    "\n",
    "\n",
    "model_path = 'DeepPavlov/rubert-base-cased'\n",
    "net = CADEC_SoTa(model_path, CV_train.thesaurus_embeddings) #, score_threshold=6.1977e-05\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net.to(device)\n",
    "print('Net loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-multiple",
   "metadata": {},
   "source": [
    "<h2>Обучение модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "realistic-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=0.0001)\n",
    "#optimizer2 = optim.AdamW(net2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fleet-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-luxembourg",
   "metadata": {},
   "source": [
    "Для большей детерменированности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "olympic-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n",
    "torch.use_deterministic_algorithms(mode=False)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adverse-poison",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 507/507 [01:21<00:00,  6.26batch/s, loss_decrease=1.0000010403159307]\n",
      "100%|██████████| 3776/3776 [00:46<00:00, 81.68batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5659427966101694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 507/507 [01:18<00:00,  6.43batch/s, loss_decrease=1.0000030263796271]\n",
      "100%|██████████| 3776/3776 [00:44<00:00, 85.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6215572033898306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 507/507 [01:20<00:00,  6.28batch/s, loss_decrease=1.0000037829773962]\n",
      "100%|██████████| 3776/3776 [00:46<00:00, 81.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6641949152542372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 507/507 [01:20<00:00,  6.26batch/s, loss_decrease=1.0000039721270173]\n",
      "100%|██████████| 3776/3776 [00:44<00:00, 84.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6816737288135594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 507/507 [01:20<00:00,  6.31batch/s, loss_decrease=1.0000039721270173]\n",
      "100%|██████████| 3776/3776 [00:44<00:00, 85.50batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.690677966101695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 507/507 [01:20<00:00,  6.32batch/s, loss_decrease=1.0000041612767099]\n",
      "100%|██████████| 3776/3776 [00:44<00:00, 85.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6983580508474576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 507/507 [01:20<00:00,  6.32batch/s, loss_decrease=1.0000043504264742]\n",
      "100%|██████████| 3776/3776 [00:45<00:00, 83.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7094809322033897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 507/507 [01:20<00:00,  6.32batch/s, loss_decrease=1.0000043504264742]\n",
      "100%|██████████| 3776/3776 [00:44<00:00, 84.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190148305084746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 507/507 [01:18<00:00,  6.44batch/s, loss_decrease=1.0000044450013832]\n",
      "100%|██████████| 3776/3776 [00:43<00:00, 86.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7171610169491526\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "batch_size=16\n",
    "trainloader = torch.utils.data.DataLoader(RDR_train, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(RDR_test_without_conceptless, batch_size=1, shuffle=False)\n",
    "\n",
    "net.train()\n",
    "initial_loss = None\n",
    "for epoch in range(1, 10):\n",
    "    net.train()\n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "        for data in tepoch:\n",
    "\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            labels = data['one_hot_labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if device=='cuda':\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = net(inputs)['output']\n",
    "                    loss = criterion(outputs, labels)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                outputs = net(inputs)['output']\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            if initial_loss is None:\n",
    "                initial_loss = loss.item()\n",
    "            tepoch.set_postfix(loss_decrease = str(initial_loss/loss.item()))\n",
    "    net.eval()\n",
    "    model_answers=[]\n",
    "    real_answers=[]\n",
    "    with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "        for data in eval_process:\n",
    "\n",
    "            #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "            inputs = data['tokenized_phrases']\n",
    "            #labels = data['one_hot_labels']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs_dict = net(inputs)\n",
    "                #outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "                pred_meddra_code = CV_test_without_conceptless.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "            model_answers.append(pred_meddra_code)\n",
    "            real_answers.append(data['label_codes'])\n",
    "\n",
    "    print(f1_score(real_answers, model_answers, average='micro'))\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interior-beatles",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'rubert_trained_9ep_context.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-rochester",
   "metadata": {},
   "source": [
    "<h2>Другие метрики</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "processed-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3776/3776 [00:44<00:00, 84.67batch/s]\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 weighted: 0.6961701909172502\n",
      "f1 micro: 0.7171610169491526\n",
      "f1 macro: 0.1932677237159497\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "out_of_voc_set = set(test_concepts) - set(train_concepts)\n",
    "\n",
    "phrases=[]\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "model_terms=[]\n",
    "real_terms=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test_without_conceptless, batch_size=1, shuffle=False)\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_dict = net(inputs)\n",
    "            #outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "            pred_meddra_code = CV_test_without_conceptless.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "        phrases.append(data['phrases'][0])\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'][0])\n",
    "        model_terms.append(CV_test_without_conceptless.meddra_code_to_meddra_term[pred_meddra_code])\n",
    "        real_terms.append(data['label_terms'][0])\n",
    "        \n",
    "res_d = classification_report(real_answers, model_answers, output_dict=True)\n",
    "print('f1 weighted: %s'%res_d['weighted avg']['f1-score'])\n",
    "print('f1 micro: %s'%res_d['accuracy'])\n",
    "print('f1 macro: %s'%res_d['macro avg']['f1-score'])\n",
    "\n",
    "df = pd.DataFrame(columns=['phrase', 'system output', 'gold markup', 'pred term', 'gold term', 'out_of_voc'])\n",
    "for phrase, m_a, g_a, m_t, g_t in zip(phrases, model_answers, real_answers, model_terms, real_terms):\n",
    "    out_of_voc = 'yes' if g_a in out_of_voc_set else 'no'\n",
    "    new_row = pd.DataFrame({'phrase': [phrase], 'system output': [m_a], \n",
    "                            'gold markup': [g_a], 'pred term': [m_t], 'gold term': [g_t], 'out_of_voc': out_of_voc})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    \n",
    "df.to_csv('rubert_9ep_best_context_out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "medium-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 weighted in: 0.7406862887048763\n",
      "f1 micro in: 0.7544642857142857\n",
      "f1 macro in: 0.2717403398963569\n",
      "f1 weighted out: 0.027157738095238096\n",
      "f1 micro out: 0.020833333333333332\n",
      "f1 macro out: 0.009507557289127255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/romanrybka/.conda/envs/latest_torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "df_out = df[df['out_of_voc']=='yes']\n",
    "df_in = df[df['out_of_voc']=='no']\n",
    "\n",
    "res_d_in = classification_report(df_in['gold markup'], df_in['system output'], output_dict=True)\n",
    "res_d_out = classification_report(df_out['gold markup'], df_out['system output'], output_dict=True)\n",
    "\n",
    "print('f1 weighted in: %s'%res_d_in['weighted avg']['f1-score'])\n",
    "print('f1 micro in: %s'%res_d_in['accuracy'])\n",
    "print('f1 macro in: %s'%res_d_in['macro avg']['f1-score'])\n",
    "\n",
    "print('f1 weighted out: %s'%res_d_out['weighted avg']['f1-score'])\n",
    "print('f1 micro out: %s'%res_d_out['accuracy'])\n",
    "print('f1 macro out: %s'%res_d_out['macro avg']['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-sapphire",
   "metadata": {},
   "source": [
    "Тест conceptless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thrown-norway",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3995/3995 [00:40<00:00, 99.05batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.683854818523154"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs_dict = net(inputs)\n",
    "            outputs_dict.label_concepless_tensors(score_treshold = 6.1977e-05)\n",
    "            pred_meddra_code = CV_test.meddra_codes[outputs_dict['output'].argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intimate-karma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.083883285522461"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "developmental-liverpool",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.083832740783691"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aboriginal-blocking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.083831787109375"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "criminal-myanmar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-shower",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "brave-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1749/1749 [00:20<00:00, 83.56batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8147512864493998"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        #labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-share",
   "metadata": {},
   "source": [
    "<h2>Тест модели с mean_pooling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "checked-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:17<00:00, 98.77batch/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7994285714285714"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dominant-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:21<00:00, 81.52batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "assumed-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:20<00:00, 87.42batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.792"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'][0])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-reach",
   "metadata": {},
   "source": [
    "<h2> Тест необученной модели (на всякий случай) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "attempted-growth",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:05<00:00, 294.15batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17142857142857143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "#net.train()\n",
    "net.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-arbor",
   "metadata": {},
   "source": [
    "<h2>Инференс</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "difficult-array",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase: температурой 37,8\n",
      "model: Пирексия\n",
      "real: Пирексия\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "i = randint(1, len(RDR_test))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "phrase = {k: tensor.unsqueeze(0) for k, tensor in RDR_test[i]['tokenized_phrases'].items()}\n",
    "concept = RDR_test[i]['label_codes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_answer = CV.meddra_codes[net(phrase).argmax()]\n",
    "    \n",
    "\n",
    "\n",
    "print('phrase: %s'%RDR_test[i]['phrases'])\n",
    "print('model: %s'%CV.meddra_code_to_meddra_term[model_answer])\n",
    "\n",
    "\n",
    "\n",
    "print('real: %s'%RDR_test[i]['label_terms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-continuity",
   "metadata": {},
   "source": [
    "Где ошиблась модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "nominated-constraint",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:19<00:00, 88.99batch/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>раздрожалась</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>чувство тревоги</td>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>угнетенном состоянии</td>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Начала плохо спать</td>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ухудшилось эмоциональное состояние</td>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>проблема с кожей на лице</td>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>шаткая нервная система</td>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>острой респираторной вирусной инфекции</td>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>с гнойно-слизистым секретом</td>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>37,3</td>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     phrase system output gold markup\n",
       "0                              раздрожалась      10025482    10022998\n",
       "1                           чувство тревоги      10033670    10002855\n",
       "2                      угнетенном состоянии      10025482    10040007\n",
       "3                        Начала плохо спать      10022437    10062519\n",
       "4        ухудшилось эмоциональное состояние      10061284    10014551\n",
       "..                                      ...           ...         ...\n",
       "359                проблема с кожей на лице      10015150    10000496\n",
       "360                  шаткая нервная система      10029216    10003549\n",
       "361  острой респираторной вирусной инфекции      10074831    10062352\n",
       "362             с гнойно-слизистым секретом      10023848    10039083\n",
       "363                                    37,3      10037660    10005911\n",
       "\n",
       "[364 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#net = torch.load('./cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')['param_groups']\n",
    "\n",
    "net.eval()\n",
    "\n",
    "model_wrong_answers = []\n",
    "gold_truth_answers = []\n",
    "phrases = []\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "        #tepoch.set_description(f\"Progress\")\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[net(inputs).argmax()]\n",
    "        \n",
    "        if str(pred_meddra_code)!=str(data['label_codes'][0]):\n",
    "            model_wrong_answers.append(pred_meddra_code)\n",
    "            gold_truth_answers.append(data['label_codes'][0])\n",
    "            phrases.append(data['phrases'][0])\n",
    "        #model_wrong_answers\n",
    "        #model_answers.append(pred_meddra_code)\n",
    "        #real_answers.append(data['label_codes'])\n",
    "        \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['phrase', 'system output', 'gold markup'])\n",
    "\n",
    "for phrase, m_a, g_a in zip(phrases, model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'phrase': [phrase], 'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "welcome-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "played-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.meddra_code_to_meddra_term['CONCEPT_LESS'] = 'CONCEPT_LESS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ultimate-freeze",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>для профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>профилактики</td>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "      <td>Профилактика</td>\n",
       "      <td>Профилактика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>стрессы</td>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "      <td>Стресс</td>\n",
       "      <td>Стресс</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>тревожности</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10033670</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Паническая реакция</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>ослабленного иммунитета</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10021425</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Нарушение со стороны иммунной системы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>чихал</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10041232</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Чихание</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>кашлял</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>10011224</td>\n",
       "      <td>CONCEPT_LESS</td>\n",
       "      <td>Кашель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>температура</td>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "      <td>Повышенная температура тела</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       phrase system output  gold markup  \\\n",
       "0                профилактики      10036898     10036898   \n",
       "1            для профилактики      10036898     10036898   \n",
       "2                профилактики      10036898     10036898   \n",
       "3                профилактики      10036898     10036898   \n",
       "4                     стрессы      10042209     10042209   \n",
       "...                       ...           ...          ...   \n",
       "1745              тревожности  CONCEPT_LESS     10033670   \n",
       "1746  ослабленного иммунитета  CONCEPT_LESS     10021425   \n",
       "1747                    чихал  CONCEPT_LESS     10041232   \n",
       "1748                   кашлял  CONCEPT_LESS     10011224   \n",
       "1749              температура      10005911     10005911   \n",
       "\n",
       "                   system concept                           gold concept  \n",
       "0                    Профилактика                           Профилактика  \n",
       "1                    Профилактика                           Профилактика  \n",
       "2                    Профилактика                           Профилактика  \n",
       "3                    Профилактика                           Профилактика  \n",
       "4                          Стресс                                 Стресс  \n",
       "...                           ...                                    ...  \n",
       "1745                 CONCEPT_LESS                     Паническая реакция  \n",
       "1746                 CONCEPT_LESS  Нарушение со стороны иммунной системы  \n",
       "1747                 CONCEPT_LESS                                Чихание  \n",
       "1748                 CONCEPT_LESS                                 Кашель  \n",
       "1749  Повышенная температура тела            Повышенная температура тела  \n",
       "\n",
       "[1750 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('elastic_wrong_predictions.csv')\n",
    "df['system concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['system output'])], axis=1)#], join='outer', ignore_index=True)\n",
    "df['gold concept'] = df.apply(lambda x: CV.meddra_code_to_meddra_term[str(x['gold markup'])], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "foreign-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong = df[df['system output'].apply(lambda x: int(x) if x!='CONCEPT_LESS' else 'CONCEPT_LESS')!=df['gold markup']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "based-voluntary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "      <th>system concept</th>\n",
       "      <th>gold concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phrase, system output, gold markup, system concept, gold concept]\n",
       "Index: []"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wrong[df_wrong['system output']!='CONCEPT_LESS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "established-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wrong.to_csv('elastic_RDR_wrong.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fleet-thought",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "1745    True\n",
       "1746    True\n",
       "1747    True\n",
       "1748    True\n",
       "1749    True\n",
       "Length: 1750, dtype: bool"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "occupational-homeless",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           10036898\n",
       "1           10036898\n",
       "2           10036898\n",
       "3           10036898\n",
       "4           10042209\n",
       "            ...     \n",
       "1745    CONCEPT_LESS\n",
       "1746    CONCEPT_LESS\n",
       "1747    CONCEPT_LESS\n",
       "1748    CONCEPT_LESS\n",
       "1749        10005911\n",
       "Name: system output, Length: 1750, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['system output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "alleged-finding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       10036898\n",
       "1       10036898\n",
       "2       10036898\n",
       "3       10036898\n",
       "4       10042209\n",
       "          ...   \n",
       "1745    10033670\n",
       "1746    10021425\n",
       "1747    10041232\n",
       "1748    10011224\n",
       "1749    10005911\n",
       "Name: gold markup, Length: 1750, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "streaming-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('rubert_base_wrong_preds_RDR.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baking-police",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10022998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10002855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10025482</td>\n",
       "      <td>10040007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10022437</td>\n",
       "      <td>10062519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10061284</td>\n",
       "      <td>10014551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>10015150</td>\n",
       "      <td>10000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>10029216</td>\n",
       "      <td>10003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>10074831</td>\n",
       "      <td>10062352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>10023848</td>\n",
       "      <td>10039083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>10037660</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output  gold markup\n",
       "0         10025482     10022998\n",
       "1         10033670     10002855\n",
       "2         10025482     10040007\n",
       "3         10022437     10062519\n",
       "4         10061284     10014551\n",
       "..             ...          ...\n",
       "359       10015150     10000496\n",
       "360       10029216     10003549\n",
       "361       10074831     10062352\n",
       "362       10023848     10039083\n",
       "363       10037660     10005911\n",
       "\n",
       "[364 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sharp-pledge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system output</th>\n",
       "      <th>gold markup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10036898</td>\n",
       "      <td>10036898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10042209</td>\n",
       "      <td>10042209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>10033670</td>\n",
       "      <td>10033670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>10021425</td>\n",
       "      <td>10021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>10041232</td>\n",
       "      <td>10041232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>10011224</td>\n",
       "      <td>10011224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>10005911</td>\n",
       "      <td>10005911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     system output gold markup\n",
       "0         10036898    10036898\n",
       "1         10036898    10036898\n",
       "2         10036898    10036898\n",
       "3         10036898    10036898\n",
       "4         10042209    10042209\n",
       "...            ...         ...\n",
       "1745      10033670    10033670\n",
       "1746      10021425    10021425\n",
       "1747      10041232    10041232\n",
       "1748      10011224    10011224\n",
       "1749      10005911    10005911\n",
       "\n",
       "[1750 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['system output', 'gold markup'])\n",
    "\n",
    "for m_a, g_a in zip(model_wrong_answers, gold_truth_answers):\n",
    "    new_row = pd.DataFrame({'system output': [m_a], 'gold markup': [g_a]})\n",
    "    df = pd.concat([df, new_row], join='inner', ignore_index=True)\n",
    "    #gold_truth_answers.append(g_a)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "laughing-palestinian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['state', 'param_groups'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-worse",
   "metadata": {},
   "source": [
    "<h2>Сохранение и загрузка модели</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "primary-psychology",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, './cadec_SoTa_on_RDR_rubert_base_2_epoch.pt')\n",
    "torch.save(optimizer.state_dict(), './cadec_SoTa_on_RDR_rubert_base_2_epoch_opt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "lightweight-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_model = torch.load('./cadec_SoTa_on_RDR_rubert_right_exp.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-steam",
   "metadata": {},
   "source": [
    "Покажем, что это ТА ЖЕ модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "professional-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1750/1750 [00:06<00:00, 259.93batch/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5891428571428572"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_model.eval()\n",
    "\n",
    "model_answers=[]\n",
    "real_answers=[]\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(RDR_test, batch_size=1,\n",
    "                                          shuffle=False)\n",
    "\n",
    "\n",
    "with tqdm(testloader, unit=\"batch\") as eval_process:\n",
    "    for data in eval_process:\n",
    "\n",
    "\n",
    "        inputs = data['tokenized_phrases']\n",
    "        labels = data['one_hot_labels']\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_meddra_code = CV.meddra_codes[the_model(inputs).argmax()]\n",
    "\n",
    "\n",
    "        model_answers.append(pred_meddra_code)\n",
    "        real_answers.append(data['label_codes'])\n",
    "\n",
    "f1_score(real_answers, model_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-freeze",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normalization env",
   "language": "python",
   "name": "latest_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
