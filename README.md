# MedNormalization
Репозиторий для разработке методов нормализации, или entity linking - соотнесения упоминаний из текстов с концептами из словарей и классификаторов. 

# Структура репозитория
## Data
Формат хранения данных, используемые корпуса (и их веврсии), используемые словари должны быть описаны в Data/README.md.

## Реализации методов нормализации

Разные реализации будут в отдельных папках в одном репозитории. Здесь их краткое описание можно привести со ссылками.

Можно положить в этот же репозиторий папки EntityNormalization_Elastic, EntityNormalization_SiamNN, EntityNormalization_W2V, MetaDialogNastyaGlebMap, с прошлыми наработками по нормализации из соответствующих репозиториев. Но это имеет смысл делать только если пробовать запускать эти механизмы на этом корпусе. Прошлые точности по ним, кстати тут (https://docs.google.com/spreadsheets/d/1RDfygKFgIqcMqQ2U-NavZxU86gndQ8sESjFTUD8e4TQ/edit#gid=250959241 )

## Актуальные задачи по подготовке данных:

1 проверить слегка разметку, че там разметчики наделали, нет ли каких-то моментов, требующих внимания. Это сделал для всего кроме адр и индикейшн. Были моменты, которые пришлось править (некорректно написанные коды, коды с которыми я не согласен, косая черта вместо прямой при альтернативных вариантах итп). объединил разметку, которая делалась для двух корпусов в одну таблицу. А так, ждём теперь АДР, Индикейшн. А, только я не проверял на то, всегда ли похожие на мой взгляд сущности имеют одинаковые классы, потому что мне попадались такие, где были разные (из разных корпусов просто были)

2 драгкласс надо дать на перепроверку разметчикам.

3 сформулировать и зафиксировать, как делаем разбивку на трейн, валид, тест.

4 как-то посчитать агримент, есть версии пересекающиеся немного от разных разметчиков и есть версии в завимисмости от времени.

5 Посчитать, сколько случаев, когда есть несколько альтернативных вариантов, можно ли их проигнорировать.

6 В issue постараться вспомнить, какие вопросы возникали по разметке и какие проблемы могут возникнуть, например фразы, нормализация которых понятна только в контексте

# Обзор литературы и выбор метода
Здесь собираются корпуса и достигнутые на них точности. https://docs.google.com/spreadsheets/d/18Y4QgS2P5FxRPShKPsapPfBptUBs_q17LZ_i7tePeLo/edit#gid=1821727344 

Обзор методов есть здесь https://docs.google.com/document/d/1PKl-MIZ2pICjrYl76PR2xnB9WcpqUpbl4WafL8-nZT8/edit 

В принципе методы у всех схожие, есть энкодер, состоящий из эмбеддинга + вариативных частей в виде доп признаков и последующих слоёв, которые могут быть LSTM/Conv/Transformer или что-то подобное. Так кодируется входное упоминание или текст. Потом есть эмбеддинг для словаря, который может быть обучаемый, или предобученный (разными способами), пошареный с входным эмбеддингом. И есть процедура выбора подходящего термина из словаря, по метрике или слоем каким-то (аттеншен или просто денс, то есть скалярным произведением).

1 Добавить в таблицу с корпусами информацию по TwiMed, PsyTar, TwADR-S, TwADR-L, n2c2 2019, SemEval-2015. 

2 Было бы неплохо собрать в таблицу или схему как раз все эти вариации, которые возможно по следующим категориям:
- как обучается входной эмбеддинг
- что идёт после эмбеддинга
- какие есть дополнительные входные признаки кроме текста, пропускаемого через эмбеддинг
- как обучается эмбеддинг словаря
- какая процедура линкования двух векторов.

3 Можно еще вот здесь что-то подобрать, посмотреть: https://paperswithcode.com/task/entity-linking , потому что суть задачи вроде та же. Но там нет медицинских корпусов и по каждому корпусу по одной работе. Так что как выбирать и сравнивать не понятно, если только всё читать и на свой вкус выбирать.

4 Подготовить другие корпуса
Из тех, корпусов, которые собраны в таблице https://docs.google.com/spreadsheets/d/18Y4QgS2P5FxRPShKPsapPfBptUBs_q17LZ_i7tePeLo/edit#gid=1821727344 выбрать какие-то на которых будем сравниваться и привести их к нашему формату.

# Разработка собственной системы.
## Формализация задачи
Ну основная формализация, которую можно рассматривать такая: есть текст, есть в нём упоминания выделенные, надо в соответствие каждому упоминанию выбрать код который проставили разметчики.

Какие могут быть вариации:
 - можно рассматривать только упоминание без окружающего текста. Так задача будет сложней, но возможно это единственный вариант, который можно рассматривать для корпуса росздрава (а может и нет, там есть какая-то доп инфа, если адр в ней упомянут, то можно и этот текст задействовать).
- можно наборот классифицировать (мультилейбл) весь текст, указывая, какие коды в нём есть, без их точного положения в тексте. Это может тоже в росздраве с доп. инфой сработает. 
- Отдельно по каждому типу, или по каждому словарю, или всё вместе сразу?
## Метрика
Самый простой и правильный вариант: F1 score по классам. Micro и Macro. Precision и recall наверно не нужны. 

Варианты для исследования:
- При второй формулировке задачи можно еще рассматривать только уникальные упоминания, но это лишняя заморочка. Не стоит на это тратить время.
- В некоторых работах еще делают оценку с учётом ограниченного количество классов для выбора,например только те, которые есть в корпусе. 
- Мы еще делали оценки по тому, попал ли  нужный класс в топ N выдаваемых классов.
- Можно еще с учётом иерархической структуры как-то считать, например точности по определённому уровню классификации, типо по PT такая ошибка, по HGLT ниже.
- Таблицы перепутываний классов имеет смысл строить, чтоб определять какие между собой путаются. 

Задачи.
1.1 определиться, будем ли мы рассматривать разные формализации, или только одну.

1.2  Выбрать какие метрики мы планируем использовать. Все или только самые важные.

1.3. Может глянуть, где другие метрики используют?

1.3 написать скрипт метрики. На вход тест, трейн или валид корпус в эталонном формате + файл предиктов (в каком формате?), на выходе нужные метрики.
## Разработка метода.
Для создания модели под наш корпус имеет смысл проводить эксперименты по следующим направлениям
- как обучается входной эмбеддинг. Эмбеддинг языковой модели обучается сразу на нашем корпусе, или делать предобучение на целевую тематику.
- что идёт после эмбеддинга. ну тут экспериментировать особо нечего, трансформеры, вопрос только в размере. Наверно tiny bert, чтоб быстрее и проще.
- какие есть дополнительные входные признаки кроме текста, пропускаемого через эмбеддинг
- как обучается эмбеддинг словаря. Самый простой вариант, можно как бейзлайн - веса шарятся с входным эмбеддингом. Как вариант - из гугла напарсить определений к терминам или какой-то корпус с терминами и соответственно из них языковой моделью получить эмбеддинги.







